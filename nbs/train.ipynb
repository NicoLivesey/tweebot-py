{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicolas/anaconda3/envs/tweebot/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/nicolas/anaconda3/envs/tweebot/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/nicolas/anaconda3/envs/tweebot/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/nicolas/anaconda3/envs/tweebot/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/nicolas/anaconda3/envs/tweebot/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/nicolas/anaconda3/envs/tweebot/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/nicolas/anaconda3/envs/tweebot/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/nicolas/anaconda3/envs/tweebot/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/nicolas/anaconda3/envs/tweebot/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/nicolas/anaconda3/envs/tweebot/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/nicolas/anaconda3/envs/tweebot/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/nicolas/anaconda3/envs/tweebot/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import gpt_2_simple as gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"../data/tweets_train.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/nicolas/anaconda3/envs/tweebot/lib/python3.6/site-packages/gpt_2_simple/src/sample.py:17: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Loading checkpoint ../models/checkpoint/hugo/hugo-romans/model-0\n",
      "WARNING:tensorflow:From /home/nicolas/anaconda3/envs/tweebot/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ../models/checkpoint/hugo/hugo-romans/model-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset has 79277 tokens\n",
      "Training...\n",
      "Saving ../models/checkpoint/hugo/hugo-romans/model-0\n",
      "[10 | 90.38] loss=3.38 avg=3.38\n",
      "[20 | 176.59] loss=3.16 avg=3.27\n",
      "[30 | 263.25] loss=2.96 avg=3.17\n",
      "[40 | 350.48] loss=2.88 avg=3.09\n",
      "[50 | 437.52] loss=2.81 avg=3.04\n",
      "[60 | 524.71] loss=2.75 avg=2.99\n",
      "[70 | 615.34] loss=2.56 avg=2.92\n",
      "[80 | 705.62] loss=2.40 avg=2.86\n",
      "[90 | 792.36] loss=2.36 avg=2.80\n",
      "[100 | 879.18] loss=2.10 avg=2.73\n",
      "======== SAMPLE 3 ========\n",
      " de l'Étoile pour qu'il p\n",
      "\n",
      "[110 | 967.66] loss=2.19 avg=2.67\n",
      "[120 | 1054.27] loss=2.00 avg=2.62\n",
      "[130 | 1140.78] loss=1.90 avg=2.56\n",
      "[140 | 1227.49] loss=1.82 avg=2.50\n",
      "[150 | 1314.16] loss=1.48 avg=2.43\n",
      "[160 | 1400.70] loss=1.38 avg=2.36\n",
      "[170 | 1487.44] loss=1.28 avg=2.29\n",
      "[180 | 1574.52] loss=1.34 avg=2.23\n",
      "[190 | 1661.36] loss=0.88 avg=2.15\n",
      "[200 | 1748.27] loss=0.69 avg=2.07\n",
      "======== SAMPLE 3 ========\n",
      "||cffffccino_|cffffccino_|cffffcc\n",
      "\n",
      "[210 | 1835.24] loss=0.68 avg=2.00\n",
      "[220 | 1921.99] loss=0.63 avg=1.93\n",
      "[230 | 2008.85] loss=0.58 avg=1.87\n",
      "[240 | 2095.69] loss=0.56 avg=1.81\n",
      "[250 | 2182.63] loss=0.39 avg=1.74\n",
      "[260 | 2269.59] loss=0.40 avg=1.68\n",
      "[270 | 2356.52] loss=0.26 avg=1.62\n",
      "[280 | 2443.24] loss=0.27 avg=1.57\n",
      "[290 | 2529.95] loss=0.24 avg=1.52\n",
      "[300 | 2616.69] loss=0.19 avg=1.46\n",
      "======== SAMPLE 3 ========\n",
      " une|<|endoftext|>Une\n",
      "\n",
      "[310 | 2703.68] loss=0.19 avg=1.42\n",
      "[320 | 2790.43] loss=0.18 avg=1.37\n",
      "[330 | 2877.29] loss=0.14 avg=1.33\n",
      "[340 | 2964.09] loss=0.16 avg=1.29\n",
      "[350 | 3050.94] loss=0.13 avg=1.25\n",
      "[360 | 3137.72] loss=0.11 avg=1.21\n",
      "[370 | 3224.44] loss=0.10 avg=1.18\n",
      "[380 | 3311.24] loss=0.09 avg=1.14\n",
      "[390 | 3398.12] loss=0.08 avg=1.11\n",
      "[400 | 3484.88] loss=0.07 avg=1.08\n",
      "======== SAMPLE 3 ========\n",
      "u>quand je suis arrivé sur\n",
      "\n",
      "[410 | 3571.89] loss=0.10 avg=1.05\n",
      "[420 | 3659.02] loss=0.07 avg=1.02\n",
      "[430 | 3745.83] loss=0.07 avg=0.99\n",
      "[440 | 3832.51] loss=0.06 avg=0.97\n",
      "[450 | 3919.03] loss=0.07 avg=0.94\n",
      "[460 | 4005.78] loss=0.07 avg=0.92\n",
      "[470 | 4092.49] loss=0.07 avg=0.90\n",
      "[480 | 4179.20] loss=0.06 avg=0.87\n",
      "[490 | 4266.06] loss=0.06 avg=0.85\n",
      "[500 | 4352.96] loss=0.06 avg=0.83\n",
      "Saving ../models/checkpoint/hugo/hugo-romans/model-500\n",
      "WARNING:tensorflow:From /home/nicolas/anaconda3/envs/tweebot/lib/python3.6/site-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "======== SAMPLE 3 ========\n",
      " dendorme en grosse — ou qu\n",
      "\n",
      "[510 | 4441.49] loss=0.06 avg=0.81\n",
      "[520 | 4528.21] loss=0.06 avg=0.80\n",
      "[530 | 4615.32] loss=0.05 avg=0.78\n",
      "[540 | 4702.26] loss=0.06 avg=0.76\n",
      "[550 | 4789.26] loss=0.06 avg=0.74\n",
      "[560 | 4876.28] loss=0.06 avg=0.73\n",
      "[570 | 4963.20] loss=0.05 avg=0.71\n",
      "[580 | 5050.09] loss=0.05 avg=0.70\n",
      "[590 | 5137.00] loss=0.06 avg=0.68\n",
      "[600 | 5223.91] loss=0.04 avg=0.67\n",
      "======== SAMPLE 3 ========\n",
      "�ais mon hémorragie avait \n",
      "\n",
      "[610 | 5311.04] loss=0.04 avg=0.65\n",
      "[620 | 5397.98] loss=0.04 avg=0.64\n",
      "[630 | 5484.85] loss=0.05 avg=0.63\n",
      "[640 | 5571.79] loss=0.05 avg=0.62\n",
      "[650 | 5658.66] loss=0.04 avg=0.60\n",
      "[660 | 5745.54] loss=0.04 avg=0.59\n",
      "[670 | 5832.44] loss=0.04 avg=0.58\n",
      "[680 | 5919.28] loss=0.04 avg=0.57\n",
      "[690 | 6005.93] loss=0.05 avg=0.56\n",
      "[700 | 6092.89] loss=0.03 avg=0.55\n",
      "======== SAMPLE 3 ========\n",
      "och>T'as une étude sur �\n",
      "\n",
      "[710 | 6180.10] loss=0.04 avg=0.54\n",
      "[720 | 6266.82] loss=0.05 avg=0.53\n",
      "[730 | 6353.72] loss=0.05 avg=0.52\n",
      "[740 | 6440.24] loss=0.05 avg=0.51\n",
      "[750 | 6526.83] loss=0.04 avg=0.50\n",
      "[760 | 6613.56] loss=0.04 avg=0.49\n",
      "[770 | 6700.67] loss=0.04 avg=0.49\n",
      "[780 | 6787.54] loss=0.04 avg=0.48\n",
      "[790 | 6874.39] loss=0.05 avg=0.47\n",
      "[800 | 6961.33] loss=0.06 avg=0.46\n",
      "======== SAMPLE 3 ========\n",
      "ignendre de leur ave dans le\n",
      "\n",
      "[810 | 7048.39] loss=0.04 avg=0.45\n",
      "interrupted\n",
      "Saving ../models/checkpoint/hugo/hugo-romans/model-816\n"
     ]
    }
   ],
   "source": [
    "sess = gpt2.start_tf_sess()\n",
    "gpt2.finetune(sess,\n",
    "              dataset=train_path,\n",
    "              model_name='romans',\n",
    "              model_dir='../models/checkpoint/',\n",
    "              steps=2000,\n",
    "              batch_size=8,\n",
    "              restore_from='latest', #change to 'latest' if restarting fine-tuning from saved checkpoint\n",
    "              checkpoint_dir = \"../models/checkpoint/hugo/\", #if wanting to save checkpoints\n",
    "              run_name='hugo-romans',\n",
    "              print_every=10,\n",
    "              learning_rate=6e-5,\n",
    "              sample_every=100,\n",
    "              sample_length=10,\n",
    "              sample_num=3,\n",
    "              save_every=500, #if the fine-tuning is very slow, lower this number \n",
    "              overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2.reset_session(sess)\n",
    "del sess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint ../models/checkpoint/hugo/hugo-romans/model-816\n",
      "WARNING:tensorflow:From /home/nicolas/anaconda3/envs/tweebot/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ../models/checkpoint/hugo/hugo-romans/model-816\n",
      "CPU times: user 4.11 s, sys: 984 ms, total: 5.09 s\n",
      "Wall time: 5.04 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sess = gpt2.start_tf_sess()\n",
    "gpt2.load_gpt2(sess, \n",
    "               run_name='hugo-romans', \n",
    "               checkpoint_dir=\"../models/checkpoint/hugo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['À présent je ne pense que « faire passer la distance chez les gens »',\n",
       " \"Mais ofc la rumeur c'est même connu c'est bien, l'août était trop énergie ;))))))))))\",\n",
       " \"Ho ptdr we all L physicalement en préavis :o jamais ils m'incommodentient l'isol interdit\",\n",
       " \"gouvernement d'utilité pour que la distance ne dilate pas\",\n",
       " 'non mais gouvernement simplement directement',\n",
       " 'Force de dire que ça a un impact presque',\n",
       " \"changement la pauvre il a plus le peu de honte à l'aider mais de l'épager là\",\n",
       " \"Sauf que t'en consommes un par des gens ça {Ont la force, la faim the guitare\",\n",
       " \"Force de dire que t'es contre l'intensité de ses temps :/\",\n",
       " \"pi jsp que ça a personne de à cheval à l'intérieur ?\",\n",
       " 'Dans ton métier vous avez vraiment besoin de humanité ',\n",
       " \"Oui mais dans ton métier je vais pas chez ma mif pour t'assurer de fumeré et de l'enzer envolant tes doigts :)))\",\n",
       " \"Y a une file d'attente pour fumer une doigt vraiment\",\n",
       " 'Ptdr vous dire que faut avoir douyé le posthume ',\n",
       " \"Haaaaa c'est un long chec qui développait mon doigt\",\n",
       " 'y a pas de��リギスツールク達',\n",
       " 'Donne toi le rôle de ministre, donne moi le rôle de ministre',\n",
       " 'ràf de ce que tu commences un peu à croire que je suis à cause de tes doigts :vv',\n",
       " 'C mon prestige est de manger une salade avec des doigts, un peu plus que la niveau du poulet :',\n",
       " \"Il a raison de dire que c'est une question de doir à la top copier c'est peine perdue\",\n",
       " \"J'ai réussi à te renseigner sur le matérialisme quand même :)))\",\n",
       " 'Je te dis ça, que Kernxxx compromettent le kiffeur 😔😔)',\n",
       " \"Sur le point de vue, la franchise est plus considérable, elle n'est pas considéré comme an 11/12 compensation dans le prix des kiffes d'innomme d'15€ par mois\",\n",
       " \"Sur le point de vue, le calibre y a une proportion d'année (15-17 ans) de femmes de ménages, elles n'ont rien changé à l'inverse, elles sont à mettant le droit de défendre le pillage et en trouver le kiffement inclué sur paroop :x\",\n",
       " \"Je suppose qu'il disait qu'ils ne sont pas dans le monde inconnu et que c'est une école à fumée contre vrai\",\n",
       " \"Je suppose qu'il allait mériter des doigts, aprèsDE 10pt le posthume\",\n",
       " \"Pas avoir envie d'aller voir les gens français là\",\n",
       " 'Pourquoi ils viennent de la voiture basseberry afin que laisse sauvage',\n",
       " \"Mais évidemment à tout ce qui est inachevé il y a des exceptions mais d'un écriture concentré dans les posties réelles tu peux même continuer\"]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = gpt2.generate(sess, \n",
    "                     run_name='hugo-romans', \n",
    "                     checkpoint_dir=\"../models/checkpoint/hugo\",\n",
    "                     return_as_list=True,\n",
    "                     length=2000,\n",
    "                     temperature=0.5)[0]\n",
    "text = [t for t in text.split(\"<|endoftext|>\") if len(t.split()) > 3]\n",
    "text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tweebot]",
   "language": "python",
   "name": "conda-env-tweebot-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
