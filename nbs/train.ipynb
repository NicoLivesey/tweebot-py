{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicolas/anaconda3/envs/hugobot/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/nicolas/anaconda3/envs/hugobot/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/nicolas/anaconda3/envs/hugobot/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/nicolas/anaconda3/envs/hugobot/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/nicolas/anaconda3/envs/hugobot/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/nicolas/anaconda3/envs/hugobot/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/nicolas/anaconda3/envs/hugobot/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/nicolas/anaconda3/envs/hugobot/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/nicolas/anaconda3/envs/hugobot/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/nicolas/anaconda3/envs/hugobot/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/nicolas/anaconda3/envs/hugobot/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/nicolas/anaconda3/envs/hugobot/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import gpt_2_simple as gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"../data/tweets_train.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/nicolas/anaconda3/envs/tweebot/lib/python3.6/site-packages/gpt_2_simple/src/sample.py:17: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Loading checkpoint ../models/checkpoint/hugo/hugo-romans/model-0\n",
      "WARNING:tensorflow:From /home/nicolas/anaconda3/envs/tweebot/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ../models/checkpoint/hugo/hugo-romans/model-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset has 79277 tokens\n",
      "Training...\n",
      "Saving ../models/checkpoint/hugo/hugo-romans/model-0\n",
      "[10 | 90.38] loss=3.38 avg=3.38\n",
      "[20 | 176.59] loss=3.16 avg=3.27\n",
      "[30 | 263.25] loss=2.96 avg=3.17\n",
      "[40 | 350.48] loss=2.88 avg=3.09\n",
      "[50 | 437.52] loss=2.81 avg=3.04\n",
      "[60 | 524.71] loss=2.75 avg=2.99\n",
      "[70 | 615.34] loss=2.56 avg=2.92\n",
      "[80 | 705.62] loss=2.40 avg=2.86\n",
      "[90 | 792.36] loss=2.36 avg=2.80\n",
      "[100 | 879.18] loss=2.10 avg=2.73\n",
      "======== SAMPLE 3 ========\n",
      " de l'Étoile pour qu'il p\n",
      "\n",
      "[110 | 967.66] loss=2.19 avg=2.67\n",
      "[120 | 1054.27] loss=2.00 avg=2.62\n",
      "[130 | 1140.78] loss=1.90 avg=2.56\n",
      "[140 | 1227.49] loss=1.82 avg=2.50\n",
      "[150 | 1314.16] loss=1.48 avg=2.43\n",
      "[160 | 1400.70] loss=1.38 avg=2.36\n",
      "[170 | 1487.44] loss=1.28 avg=2.29\n",
      "[180 | 1574.52] loss=1.34 avg=2.23\n",
      "[190 | 1661.36] loss=0.88 avg=2.15\n",
      "[200 | 1748.27] loss=0.69 avg=2.07\n",
      "======== SAMPLE 3 ========\n",
      "||cffffccino_|cffffccino_|cffffcc\n",
      "\n",
      "[210 | 1835.24] loss=0.68 avg=2.00\n",
      "[220 | 1921.99] loss=0.63 avg=1.93\n",
      "[230 | 2008.85] loss=0.58 avg=1.87\n",
      "[240 | 2095.69] loss=0.56 avg=1.81\n",
      "[250 | 2182.63] loss=0.39 avg=1.74\n",
      "[260 | 2269.59] loss=0.40 avg=1.68\n",
      "[270 | 2356.52] loss=0.26 avg=1.62\n",
      "[280 | 2443.24] loss=0.27 avg=1.57\n",
      "[290 | 2529.95] loss=0.24 avg=1.52\n",
      "[300 | 2616.69] loss=0.19 avg=1.46\n",
      "======== SAMPLE 3 ========\n",
      " une|<|endoftext|>Une\n",
      "\n",
      "[310 | 2703.68] loss=0.19 avg=1.42\n",
      "[320 | 2790.43] loss=0.18 avg=1.37\n",
      "[330 | 2877.29] loss=0.14 avg=1.33\n",
      "[340 | 2964.09] loss=0.16 avg=1.29\n",
      "[350 | 3050.94] loss=0.13 avg=1.25\n",
      "[360 | 3137.72] loss=0.11 avg=1.21\n",
      "[370 | 3224.44] loss=0.10 avg=1.18\n",
      "[380 | 3311.24] loss=0.09 avg=1.14\n",
      "[390 | 3398.12] loss=0.08 avg=1.11\n",
      "[400 | 3484.88] loss=0.07 avg=1.08\n",
      "======== SAMPLE 3 ========\n",
      "u>quand je suis arrivé sur\n",
      "\n",
      "[410 | 3571.89] loss=0.10 avg=1.05\n",
      "[420 | 3659.02] loss=0.07 avg=1.02\n",
      "[430 | 3745.83] loss=0.07 avg=0.99\n",
      "[440 | 3832.51] loss=0.06 avg=0.97\n",
      "[450 | 3919.03] loss=0.07 avg=0.94\n",
      "[460 | 4005.78] loss=0.07 avg=0.92\n",
      "[470 | 4092.49] loss=0.07 avg=0.90\n",
      "[480 | 4179.20] loss=0.06 avg=0.87\n",
      "[490 | 4266.06] loss=0.06 avg=0.85\n",
      "[500 | 4352.96] loss=0.06 avg=0.83\n",
      "Saving ../models/checkpoint/hugo/hugo-romans/model-500\n",
      "WARNING:tensorflow:From /home/nicolas/anaconda3/envs/tweebot/lib/python3.6/site-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "======== SAMPLE 3 ========\n",
      " dendorme en grosse — ou qu\n",
      "\n",
      "[510 | 4441.49] loss=0.06 avg=0.81\n",
      "[520 | 4528.21] loss=0.06 avg=0.80\n",
      "[530 | 4615.32] loss=0.05 avg=0.78\n",
      "[540 | 4702.26] loss=0.06 avg=0.76\n",
      "[550 | 4789.26] loss=0.06 avg=0.74\n",
      "[560 | 4876.28] loss=0.06 avg=0.73\n",
      "[570 | 4963.20] loss=0.05 avg=0.71\n",
      "[580 | 5050.09] loss=0.05 avg=0.70\n",
      "[590 | 5137.00] loss=0.06 avg=0.68\n",
      "[600 | 5223.91] loss=0.04 avg=0.67\n",
      "======== SAMPLE 3 ========\n",
      "�ais mon hémorragie avait \n",
      "\n",
      "[610 | 5311.04] loss=0.04 avg=0.65\n",
      "[620 | 5397.98] loss=0.04 avg=0.64\n",
      "[630 | 5484.85] loss=0.05 avg=0.63\n",
      "[640 | 5571.79] loss=0.05 avg=0.62\n",
      "[650 | 5658.66] loss=0.04 avg=0.60\n",
      "[660 | 5745.54] loss=0.04 avg=0.59\n",
      "[670 | 5832.44] loss=0.04 avg=0.58\n",
      "[680 | 5919.28] loss=0.04 avg=0.57\n",
      "[690 | 6005.93] loss=0.05 avg=0.56\n",
      "[700 | 6092.89] loss=0.03 avg=0.55\n",
      "======== SAMPLE 3 ========\n",
      "och>T'as une étude sur �\n",
      "\n",
      "[710 | 6180.10] loss=0.04 avg=0.54\n",
      "[720 | 6266.82] loss=0.05 avg=0.53\n",
      "[730 | 6353.72] loss=0.05 avg=0.52\n",
      "[740 | 6440.24] loss=0.05 avg=0.51\n",
      "[750 | 6526.83] loss=0.04 avg=0.50\n",
      "[760 | 6613.56] loss=0.04 avg=0.49\n",
      "[770 | 6700.67] loss=0.04 avg=0.49\n",
      "[780 | 6787.54] loss=0.04 avg=0.48\n",
      "[790 | 6874.39] loss=0.05 avg=0.47\n",
      "[800 | 6961.33] loss=0.06 avg=0.46\n",
      "======== SAMPLE 3 ========\n",
      "ignendre de leur ave dans le\n",
      "\n",
      "[810 | 7048.39] loss=0.04 avg=0.45\n",
      "interrupted\n",
      "Saving ../models/checkpoint/hugo/hugo-romans/model-816\n"
     ]
    }
   ],
   "source": [
    "sess = gpt2.start_tf_sess()\n",
    "gpt2.finetune(sess,\n",
    "              dataset=train_path,\n",
    "              model_name='romans',\n",
    "              model_dir='../models/checkpoint/',\n",
    "              steps=2000,\n",
    "              batch_size=8,\n",
    "              restore_from='latest', #change to 'latest' if restarting fine-tuning from saved checkpoint\n",
    "              checkpoint_dir = \"../models/checkpoint/hugo/\", #if wanting to save checkpoints\n",
    "              run_name='hugo-romans',\n",
    "              print_every=10,\n",
    "              learning_rate=6e-5,\n",
    "              sample_every=100,\n",
    "              sample_length=10,\n",
    "              sample_num=3,\n",
    "              save_every=500, #if the fine-tuning is very slow, lower this number \n",
    "              overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint ../models/checkpoint/hugo/hugo-romans/model-816\n",
      "WARNING:tensorflow:From /home/nicolas/anaconda3/envs/hugobot/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ../models/checkpoint/hugo/hugo-romans/model-816\n",
      "CPU times: user 5.95 s, sys: 475 ms, total: 6.42 s\n",
      "Wall time: 3.16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sess = gpt2.start_tf_sess()\n",
    "gpt2.load_gpt2(sess, \n",
    "               run_name='hugo-romans', \n",
    "               checkpoint_dir=\"../models/checkpoint/hugo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sous un pull toji capo (don Pablo) en FYI atle��:\n",
      "Bah franchement c'est un bon 8/10\n",
      "Y a une file d'attente pour boxer avec moi sur Paris 😖😖\n",
      "Dm :-)\n",
      "Je suis cursed\n",
      "En ce moment il pleut littéralement chaque fois que je veux aller courir\n",
      "Huhhh là jdois être à 75, tu voudrais faire quelle boxe ? Et t'es par où dans Lyon ?\n",
      "Abusivement ? Ils ont la main sur leurs conditions d'utilisations donc il leur suffit de les modifier pour que ce ne soit pas \"abusif\"\n",
      "Poursuivre une entreprise privée car elle supprime des données que des utilisateurs ont sciemment entré dans son système, en connaissance théorique des conditions d'utilisations ? T'y crois vraiment ?\n",
      "J'aurais pu remplacer nudité par apologie du terrorisme, racisme ou autre orrh\n",
      "tu l'as lu en anglais ou t'avais une édition française ?\n",
      "j'attends utopies réelles là il arrive mardi je vais me régaler je sens !!\n",
      "Pcq ses analyses sont rigoureuses, empiriques, matérialistes, vraiment ancrées dans le réel et que les solutions proposées (ça je ne sais pas encore, j'attends son bouquin) ont la réputation de suivre le même chemin\n",
      "trop hâte de recevoir utopies réelles!!\n",
      "juste un king Erik Olin Wright en fait\n",
      "Tu trouves ça choquant que, par exemple, Instagram censure la nudité ?\n",
      "bon bah rien de choquant alors, ils n'ont rien changé à leur fonctionnement\n",
      "Mais du coup le simple fait de modérer, ce qu'ils font déjà, est censé lever cette immunité non ?\n",
      "immunité à quoi ?\n",
      "Qui veut boxer sur Lyon svp 😖\n",
      "oui\n",
      "heaven on earth incroyable\n",
      "putain she knows elle est HAAAAAAA kid cudi &lt;3333\n",
      "Prochaine rando j'essaye, ça peut être rigolo une hémorragie à 2000m\n",
      "Perso je retire la fine pellicule de crasse avec une tête de hache 🤗\n",
      "Je pense que c'est le bon gonflement des choux bien gonflés !!\n",
      "Je te dis ça vers 1h\n",
      "Je crée l'interaction\n",
      "C SORTI PROFITEZ BIEN\n",
      "le gonflement n'est pas piqué des hannetons !\n",
      "comme les tiens ;))))\n",
      "Oui ça me rappelle les choux d'un ami commun !!\n",
      "Personne : Les choux :\n",
      "c'est super dur de trouver des choux bien gonflés par ces temps, j'espère que quelqu'un pourra photographier des choux bien gonflés !!!\n",
      "Qu'ils sont gonflés ces choux\n",
      "cette jeune fille a trouvé comment relancer l'économie merci de lui laisser votre place !!!\n",
      "Si je vois un tweet de toi sur la\n",
      "CPU times: user 1min 56s, sys: 17.6 s, total: 2min 13s\n",
      "Wall time: 48.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "text = gpt2.generate(sess, \n",
    "                     run_name='hugo-romans', \n",
    "                     checkpoint_dir=\"../models/checkpoint/hugo\",\n",
    "                     return_as_list=True,\n",
    "                     length=2000,\n",
    "                     temperature=0.5)[0]\n",
    "text = text.split(\"<|endoftext|>\")\n",
    "for t in text:\n",
    "    print(t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hugobot]",
   "language": "python",
   "name": "conda-env-hugobot-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
