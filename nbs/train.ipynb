{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicolas/anaconda3/envs/hugobot/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/nicolas/anaconda3/envs/hugobot/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/nicolas/anaconda3/envs/hugobot/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/nicolas/anaconda3/envs/hugobot/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/nicolas/anaconda3/envs/hugobot/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/nicolas/anaconda3/envs/hugobot/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/nicolas/anaconda3/envs/hugobot/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/nicolas/anaconda3/envs/hugobot/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/nicolas/anaconda3/envs/hugobot/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/nicolas/anaconda3/envs/hugobot/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/nicolas/anaconda3/envs/hugobot/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/nicolas/anaconda3/envs/hugobot/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import gpt_2_simple as gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"../data/tweets_train.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/nicolas/anaconda3/envs/tweebot/lib/python3.6/site-packages/gpt_2_simple/src/sample.py:17: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Loading checkpoint ../models/checkpoint/hugo/hugo-romans/model-0\n",
      "WARNING:tensorflow:From /home/nicolas/anaconda3/envs/tweebot/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ../models/checkpoint/hugo/hugo-romans/model-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset has 79277 tokens\n",
      "Training...\n",
      "Saving ../models/checkpoint/hugo/hugo-romans/model-0\n",
      "[10 | 90.38] loss=3.38 avg=3.38\n",
      "[20 | 176.59] loss=3.16 avg=3.27\n",
      "[30 | 263.25] loss=2.96 avg=3.17\n",
      "[40 | 350.48] loss=2.88 avg=3.09\n",
      "[50 | 437.52] loss=2.81 avg=3.04\n",
      "[60 | 524.71] loss=2.75 avg=2.99\n",
      "[70 | 615.34] loss=2.56 avg=2.92\n",
      "[80 | 705.62] loss=2.40 avg=2.86\n",
      "[90 | 792.36] loss=2.36 avg=2.80\n",
      "[100 | 879.18] loss=2.10 avg=2.73\n",
      "======== SAMPLE 3 ========\n",
      " de l'Étoile pour qu'il p\n",
      "\n",
      "[110 | 967.66] loss=2.19 avg=2.67\n",
      "[120 | 1054.27] loss=2.00 avg=2.62\n",
      "[130 | 1140.78] loss=1.90 avg=2.56\n",
      "[140 | 1227.49] loss=1.82 avg=2.50\n",
      "[150 | 1314.16] loss=1.48 avg=2.43\n",
      "[160 | 1400.70] loss=1.38 avg=2.36\n",
      "[170 | 1487.44] loss=1.28 avg=2.29\n",
      "[180 | 1574.52] loss=1.34 avg=2.23\n",
      "[190 | 1661.36] loss=0.88 avg=2.15\n",
      "[200 | 1748.27] loss=0.69 avg=2.07\n",
      "======== SAMPLE 3 ========\n",
      "||cffffccino_|cffffccino_|cffffcc\n",
      "\n",
      "[210 | 1835.24] loss=0.68 avg=2.00\n",
      "[220 | 1921.99] loss=0.63 avg=1.93\n",
      "[230 | 2008.85] loss=0.58 avg=1.87\n",
      "[240 | 2095.69] loss=0.56 avg=1.81\n",
      "[250 | 2182.63] loss=0.39 avg=1.74\n",
      "[260 | 2269.59] loss=0.40 avg=1.68\n",
      "[270 | 2356.52] loss=0.26 avg=1.62\n",
      "[280 | 2443.24] loss=0.27 avg=1.57\n",
      "[290 | 2529.95] loss=0.24 avg=1.52\n",
      "[300 | 2616.69] loss=0.19 avg=1.46\n",
      "======== SAMPLE 3 ========\n",
      " une|<|endoftext|>Une\n",
      "\n",
      "[310 | 2703.68] loss=0.19 avg=1.42\n",
      "[320 | 2790.43] loss=0.18 avg=1.37\n",
      "[330 | 2877.29] loss=0.14 avg=1.33\n",
      "[340 | 2964.09] loss=0.16 avg=1.29\n",
      "[350 | 3050.94] loss=0.13 avg=1.25\n",
      "[360 | 3137.72] loss=0.11 avg=1.21\n",
      "[370 | 3224.44] loss=0.10 avg=1.18\n",
      "[380 | 3311.24] loss=0.09 avg=1.14\n",
      "[390 | 3398.12] loss=0.08 avg=1.11\n",
      "[400 | 3484.88] loss=0.07 avg=1.08\n",
      "======== SAMPLE 3 ========\n",
      "u>quand je suis arrivé sur\n",
      "\n",
      "[410 | 3571.89] loss=0.10 avg=1.05\n",
      "[420 | 3659.02] loss=0.07 avg=1.02\n",
      "[430 | 3745.83] loss=0.07 avg=0.99\n",
      "[440 | 3832.51] loss=0.06 avg=0.97\n",
      "[450 | 3919.03] loss=0.07 avg=0.94\n",
      "[460 | 4005.78] loss=0.07 avg=0.92\n",
      "[470 | 4092.49] loss=0.07 avg=0.90\n",
      "[480 | 4179.20] loss=0.06 avg=0.87\n",
      "[490 | 4266.06] loss=0.06 avg=0.85\n",
      "[500 | 4352.96] loss=0.06 avg=0.83\n",
      "Saving ../models/checkpoint/hugo/hugo-romans/model-500\n",
      "WARNING:tensorflow:From /home/nicolas/anaconda3/envs/tweebot/lib/python3.6/site-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "======== SAMPLE 3 ========\n",
      " dendorme en grosse — ou qu\n",
      "\n",
      "[510 | 4441.49] loss=0.06 avg=0.81\n",
      "[520 | 4528.21] loss=0.06 avg=0.80\n",
      "[530 | 4615.32] loss=0.05 avg=0.78\n",
      "[540 | 4702.26] loss=0.06 avg=0.76\n",
      "[550 | 4789.26] loss=0.06 avg=0.74\n",
      "[560 | 4876.28] loss=0.06 avg=0.73\n",
      "[570 | 4963.20] loss=0.05 avg=0.71\n",
      "[580 | 5050.09] loss=0.05 avg=0.70\n",
      "[590 | 5137.00] loss=0.06 avg=0.68\n",
      "[600 | 5223.91] loss=0.04 avg=0.67\n",
      "======== SAMPLE 3 ========\n",
      "�ais mon hémorragie avait \n",
      "\n",
      "[610 | 5311.04] loss=0.04 avg=0.65\n",
      "[620 | 5397.98] loss=0.04 avg=0.64\n",
      "[630 | 5484.85] loss=0.05 avg=0.63\n",
      "[640 | 5571.79] loss=0.05 avg=0.62\n",
      "[650 | 5658.66] loss=0.04 avg=0.60\n",
      "[660 | 5745.54] loss=0.04 avg=0.59\n",
      "[670 | 5832.44] loss=0.04 avg=0.58\n",
      "[680 | 5919.28] loss=0.04 avg=0.57\n",
      "[690 | 6005.93] loss=0.05 avg=0.56\n",
      "[700 | 6092.89] loss=0.03 avg=0.55\n",
      "======== SAMPLE 3 ========\n",
      "och>T'as une étude sur �\n",
      "\n",
      "[710 | 6180.10] loss=0.04 avg=0.54\n",
      "[720 | 6266.82] loss=0.05 avg=0.53\n",
      "[730 | 6353.72] loss=0.05 avg=0.52\n",
      "[740 | 6440.24] loss=0.05 avg=0.51\n",
      "[750 | 6526.83] loss=0.04 avg=0.50\n",
      "[760 | 6613.56] loss=0.04 avg=0.49\n",
      "[770 | 6700.67] loss=0.04 avg=0.49\n",
      "[780 | 6787.54] loss=0.04 avg=0.48\n",
      "[790 | 6874.39] loss=0.05 avg=0.47\n",
      "[800 | 6961.33] loss=0.06 avg=0.46\n",
      "======== SAMPLE 3 ========\n",
      "ignendre de leur ave dans le\n",
      "\n",
      "[810 | 7048.39] loss=0.04 avg=0.45\n",
      "interrupted\n",
      "Saving ../models/checkpoint/hugo/hugo-romans/model-816\n"
     ]
    }
   ],
   "source": [
    "sess = gpt2.start_tf_sess()\n",
    "gpt2.finetune(sess,\n",
    "              dataset=train_path,\n",
    "              model_name='romans',\n",
    "              model_dir='../models/checkpoint/',\n",
    "              steps=2000,\n",
    "              batch_size=8,\n",
    "              restore_from='latest', #change to 'latest' if restarting fine-tuning from saved checkpoint\n",
    "              checkpoint_dir = \"../models/checkpoint/hugo/\", #if wanting to save checkpoints\n",
    "              run_name='hugo-romans',\n",
    "              print_every=10,\n",
    "              learning_rate=6e-5,\n",
    "              sample_every=100,\n",
    "              sample_length=10,\n",
    "              sample_num=3,\n",
    "              save_every=500, #if the fine-tuning is very slow, lower this number \n",
    "              overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint ../models/checkpoint/hugo/hugo-romans/model-816\n",
      "WARNING:tensorflow:From /home/nicolas/anaconda3/envs/hugobot/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ../models/checkpoint/hugo/hugo-romans/model-816\n",
      "CPU times: user 5.8 s, sys: 391 ms, total: 6.2 s\n",
      "Wall time: 2.99 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sess = gpt2.start_tf_sess()\n",
    "gpt2.load_gpt2(sess, \n",
    "               run_name='hugo-romans', \n",
    "               checkpoint_dir=\"../models/checkpoint/hugo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "endorme c'est cool !!!! fin i tapent autour de soi\n",
      "héhéhé muni derrière huissiere\n",
      "lin de tigre et tradingpes\n",
      "j'écoute les top spotify de l'année !\n",
      "Rainipsisme esbires de rage 🎥 🎥\n",
      "Voyons mon p'tit Gael\n",
      "Tu gallons tout comme moi dernier ^^\n",
      "Envie de jouer à DOFus de dofus ange\n",
      "vais mieux que le 5'8 raidi\n",
      "stggl j'ai 5i dans mon p'tit coeur\n",
      "Ah oui quel gaz un peu trop musicienne perdantaine mdr\n",
      "Y a une femme mdrr\n",
      "Et c'est un enchan de chocolat et il semble être un poi Heu\n",
      "gros j'ai fait comme si j'avais rien vu la première fois, je suis en préavis !\n",
      "Ma présence veut dire savaler\n",
      "J'ai 3 mètres de donation en compte, j'essaye de trouver ma chaîne là\n",
      "ah mais tu peux m'acheter une point de communication tyrannie plain dont tu meurs enfant\n",
      "L'album était super bien je mets pas mon p'tit coeur\n",
      "J'ai 3 précis qui te sers aux psychiatriels et bien plus sur le taper une certaine quantité de affection interditisement, par le ornière personne peut être condamné à cette vidéo !!!\n",
      "SALINE\n",
      "TuENTS te la finale SALINE\n",
      "Recevese coriandre\n",
      "Foaaah années de travailleURE haaaaaa\n",
      "Mangéle the tablée !!!\n",
      "3/4 p. mariage dors de gros\n",
      "hihi\n",
      "alice à l'autre\n",
      "These sérieuses de musique mosquées consiste en de là sur des racines\n",
      "Vous avez compris les débiles qui forment sur la méthode des protestants ?hang'bing gal du coup : qu'ils irontenent en terme sur leur enspection dans un groupe des corridors.\n",
      "Receves et phrasées néanmoins\n",
      "Vous avez compris les injures du coup c'est un délire, un détruire, un aute de pure inspiration dans le monde irgpez.\n",
      "Néoclassicisme être juste \"rajoutez colonnes\"\n",
      "Tu peux faire Ocaml avec Osespace, Julien Stapleton a gagné.\n",
      "Qd je passe la serpillère je mélange avec les bosses à une bassinet à cervais\n",
      "Ils en voulaient plus interrer de temps en temps les supprimés de ces dames.\n",
      "c dur la main elle a lu \" Fraudule \" password \" \" et tu l'aimes charminalement \"\n",
      "niraller la vidéo de l'État sur le marché this héhéhé\n",
      "oui c'est un truc de comprendre ça que j'ai incompatiblie ansay moi \n",
      "c'est l'intention de tuer un humilier en France lorsque j'ai trouvé la ferme à une lieue de ce billet,\n",
      "CPU times: user 1min 58s, sys: 17.8 s, total: 2min 15s\n",
      "Wall time: 48.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "text = gpt2.generate(sess, \n",
    "                     run_name='hugo-romans', \n",
    "                     checkpoint_dir=\"../models/checkpoint/hugo\",\n",
    "                     return_as_list=True,\n",
    "                     length=2000,\n",
    "                     temperature=0.9)[0]\n",
    "text = text.split(\"<|endoftext|>\")\n",
    "for t in text:\n",
    "    print(t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hugobot]",
   "language": "python",
   "name": "conda-env-hugobot-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
