{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicolas/anaconda3/envs/hugobot/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/nicolas/anaconda3/envs/hugobot/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/nicolas/anaconda3/envs/hugobot/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/nicolas/anaconda3/envs/hugobot/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/nicolas/anaconda3/envs/hugobot/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/nicolas/anaconda3/envs/hugobot/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/nicolas/anaconda3/envs/hugobot/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/nicolas/anaconda3/envs/hugobot/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/nicolas/anaconda3/envs/hugobot/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/nicolas/anaconda3/envs/hugobot/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/nicolas/anaconda3/envs/hugobot/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/nicolas/anaconda3/envs/hugobot/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import gpt_2_simple as gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"../data/tweets_train.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/nicolas/anaconda3/envs/tweebot/lib/python3.6/site-packages/gpt_2_simple/src/sample.py:17: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Loading checkpoint ../models/checkpoint/hugo/hugo-romans/model-0\n",
      "WARNING:tensorflow:From /home/nicolas/anaconda3/envs/tweebot/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ../models/checkpoint/hugo/hugo-romans/model-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset has 79277 tokens\n",
      "Training...\n",
      "Saving ../models/checkpoint/hugo/hugo-romans/model-0\n",
      "[10 | 90.38] loss=3.38 avg=3.38\n",
      "[20 | 176.59] loss=3.16 avg=3.27\n",
      "[30 | 263.25] loss=2.96 avg=3.17\n",
      "[40 | 350.48] loss=2.88 avg=3.09\n",
      "[50 | 437.52] loss=2.81 avg=3.04\n",
      "[60 | 524.71] loss=2.75 avg=2.99\n",
      "[70 | 615.34] loss=2.56 avg=2.92\n",
      "[80 | 705.62] loss=2.40 avg=2.86\n",
      "[90 | 792.36] loss=2.36 avg=2.80\n",
      "[100 | 879.18] loss=2.10 avg=2.73\n",
      "======== SAMPLE 3 ========\n",
      " de l'√âtoile pour qu'il p\n",
      "\n",
      "[110 | 967.66] loss=2.19 avg=2.67\n",
      "[120 | 1054.27] loss=2.00 avg=2.62\n",
      "[130 | 1140.78] loss=1.90 avg=2.56\n",
      "[140 | 1227.49] loss=1.82 avg=2.50\n",
      "[150 | 1314.16] loss=1.48 avg=2.43\n",
      "[160 | 1400.70] loss=1.38 avg=2.36\n",
      "[170 | 1487.44] loss=1.28 avg=2.29\n",
      "[180 | 1574.52] loss=1.34 avg=2.23\n",
      "[190 | 1661.36] loss=0.88 avg=2.15\n",
      "[200 | 1748.27] loss=0.69 avg=2.07\n",
      "======== SAMPLE 3 ========\n",
      "||cffffccino_|cffffccino_|cffffcc\n",
      "\n",
      "[210 | 1835.24] loss=0.68 avg=2.00\n",
      "[220 | 1921.99] loss=0.63 avg=1.93\n",
      "[230 | 2008.85] loss=0.58 avg=1.87\n",
      "[240 | 2095.69] loss=0.56 avg=1.81\n",
      "[250 | 2182.63] loss=0.39 avg=1.74\n",
      "[260 | 2269.59] loss=0.40 avg=1.68\n",
      "[270 | 2356.52] loss=0.26 avg=1.62\n",
      "[280 | 2443.24] loss=0.27 avg=1.57\n",
      "[290 | 2529.95] loss=0.24 avg=1.52\n",
      "[300 | 2616.69] loss=0.19 avg=1.46\n",
      "======== SAMPLE 3 ========\n",
      " une|<|endoftext|>Une\n",
      "\n",
      "[310 | 2703.68] loss=0.19 avg=1.42\n",
      "[320 | 2790.43] loss=0.18 avg=1.37\n",
      "[330 | 2877.29] loss=0.14 avg=1.33\n",
      "[340 | 2964.09] loss=0.16 avg=1.29\n",
      "[350 | 3050.94] loss=0.13 avg=1.25\n",
      "[360 | 3137.72] loss=0.11 avg=1.21\n",
      "[370 | 3224.44] loss=0.10 avg=1.18\n",
      "[380 | 3311.24] loss=0.09 avg=1.14\n",
      "[390 | 3398.12] loss=0.08 avg=1.11\n",
      "[400 | 3484.88] loss=0.07 avg=1.08\n",
      "======== SAMPLE 3 ========\n",
      "u>quand je suis arriv√© sur\n",
      "\n",
      "[410 | 3571.89] loss=0.10 avg=1.05\n",
      "[420 | 3659.02] loss=0.07 avg=1.02\n",
      "[430 | 3745.83] loss=0.07 avg=0.99\n",
      "[440 | 3832.51] loss=0.06 avg=0.97\n",
      "[450 | 3919.03] loss=0.07 avg=0.94\n",
      "[460 | 4005.78] loss=0.07 avg=0.92\n",
      "[470 | 4092.49] loss=0.07 avg=0.90\n",
      "[480 | 4179.20] loss=0.06 avg=0.87\n",
      "[490 | 4266.06] loss=0.06 avg=0.85\n",
      "[500 | 4352.96] loss=0.06 avg=0.83\n",
      "Saving ../models/checkpoint/hugo/hugo-romans/model-500\n",
      "WARNING:tensorflow:From /home/nicolas/anaconda3/envs/tweebot/lib/python3.6/site-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "======== SAMPLE 3 ========\n",
      " dendorme en grosse ‚Äî ou qu\n",
      "\n",
      "[510 | 4441.49] loss=0.06 avg=0.81\n",
      "[520 | 4528.21] loss=0.06 avg=0.80\n",
      "[530 | 4615.32] loss=0.05 avg=0.78\n",
      "[540 | 4702.26] loss=0.06 avg=0.76\n",
      "[550 | 4789.26] loss=0.06 avg=0.74\n",
      "[560 | 4876.28] loss=0.06 avg=0.73\n",
      "[570 | 4963.20] loss=0.05 avg=0.71\n",
      "[580 | 5050.09] loss=0.05 avg=0.70\n",
      "[590 | 5137.00] loss=0.06 avg=0.68\n",
      "[600 | 5223.91] loss=0.04 avg=0.67\n",
      "======== SAMPLE 3 ========\n",
      "ÔøΩais mon h√©morragie avait \n",
      "\n",
      "[610 | 5311.04] loss=0.04 avg=0.65\n",
      "[620 | 5397.98] loss=0.04 avg=0.64\n",
      "[630 | 5484.85] loss=0.05 avg=0.63\n",
      "[640 | 5571.79] loss=0.05 avg=0.62\n",
      "[650 | 5658.66] loss=0.04 avg=0.60\n",
      "[660 | 5745.54] loss=0.04 avg=0.59\n",
      "[670 | 5832.44] loss=0.04 avg=0.58\n",
      "[680 | 5919.28] loss=0.04 avg=0.57\n",
      "[690 | 6005.93] loss=0.05 avg=0.56\n",
      "[700 | 6092.89] loss=0.03 avg=0.55\n",
      "======== SAMPLE 3 ========\n",
      "och>T'as une √©tude sur ÔøΩ\n",
      "\n",
      "[710 | 6180.10] loss=0.04 avg=0.54\n",
      "[720 | 6266.82] loss=0.05 avg=0.53\n",
      "[730 | 6353.72] loss=0.05 avg=0.52\n",
      "[740 | 6440.24] loss=0.05 avg=0.51\n",
      "[750 | 6526.83] loss=0.04 avg=0.50\n",
      "[760 | 6613.56] loss=0.04 avg=0.49\n",
      "[770 | 6700.67] loss=0.04 avg=0.49\n",
      "[780 | 6787.54] loss=0.04 avg=0.48\n",
      "[790 | 6874.39] loss=0.05 avg=0.47\n",
      "[800 | 6961.33] loss=0.06 avg=0.46\n",
      "======== SAMPLE 3 ========\n",
      "ignendre de leur ave dans le\n",
      "\n",
      "[810 | 7048.39] loss=0.04 avg=0.45\n",
      "interrupted\n",
      "Saving ../models/checkpoint/hugo/hugo-romans/model-816\n"
     ]
    }
   ],
   "source": [
    "sess = gpt2.start_tf_sess()\n",
    "gpt2.finetune(sess,\n",
    "              dataset=train_path,\n",
    "              model_name='romans',\n",
    "              model_dir='../models/checkpoint/',\n",
    "              steps=2000,\n",
    "              batch_size=8,\n",
    "              restore_from='latest', #change to 'latest' if restarting fine-tuning from saved checkpoint\n",
    "              checkpoint_dir = \"../models/checkpoint/hugo/\", #if wanting to save checkpoints\n",
    "              run_name='hugo-romans',\n",
    "              print_every=10,\n",
    "              learning_rate=6e-5,\n",
    "              sample_every=100,\n",
    "              sample_length=10,\n",
    "              sample_num=3,\n",
    "              save_every=500, #if the fine-tuning is very slow, lower this number \n",
    "              overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint ../models/checkpoint/hugo/hugo-romans/model-816\n",
      "WARNING:tensorflow:From /home/nicolas/anaconda3/envs/hugobot/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ../models/checkpoint/hugo/hugo-romans/model-816\n",
      "CPU times: user 6.9 s, sys: 510 ms, total: 7.41 s\n",
      "Wall time: 4.13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sess = gpt2.start_tf_sess()\n",
    "gpt2.load_gpt2(sess, \n",
    "               run_name='hugo-romans', \n",
    "               checkpoint_dir=\"../models/checkpoint/hugo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oh zebi'w'ensain\n",
      "j'ai fait √ßa la nuit derni√®re hmmm\n",
      " shop best longuam\n",
      "Sheep >\n",
      "Artiste\n",
      "Viens de voir une heure dans l'√©glise de ‚Ä¶\n",
      " 65% des \"charles\" sont des dents, des ronds et des moustiques, et tu voudrais faire qu'elles soit le droit de r√©guler leur r√©gime dans leur compr√´sincent halte\n",
      "Il n'utilise pas de veine sur des charles qui sont suit mais qui √† chaque fois nulle part, tu restes pas en train de faire un unit√© d'effroi. Du coup t'√©coutais toujours. Poulets d'grammes, flics d' time, t'as bien de la VRAIE grape de Yarmouth un peu plus loin qu'√† Cebl√© :)\n",
      "Ho nn je vois l'refofficial swiveller Queensdata reprise\n",
      "Gratuit en point de vue politique, astuce\n",
      "Je peux en citer une qui survient reflet dans ma TL\n",
      "Sur une de ses transpilets c'est toi tout ce que tu fais c'est dommester vos macros, heures t'es surtout c'est un Ta√Ød√©.\n",
      "vais aller faire du slush\n",
      "J'vais t'en occuper desasted up'un qu'on te m√©fite rien de faut, tu te raisoncins une fois :ppp\n",
      "J'aurais gagn√© le ‚Äì stock data-driven marketing ‚Äì J'aurais bien r√©pondu mais les fa√ßons de tes mails c'est me demandant des 5% de choses d'horribles fois que l'on me suis dit que je tuerais te affirmer √† tuer des gens quant √† quoi s'adorezr les chiffres ?\n",
      "Mon st Antony avait juste r√©pondu par une disant\n",
      "J'ai litt√©ralement WALLP wsh\n",
      "Aucun chr√©tien ne veut rien au caract√©ris√©ment de l'id√©ologie mais homme :o\n",
      "Les testaments du physique ont √©t√© utilis√© en Brexit\n",
      "Tout √©tait tr√®s dr√¥le\n",
      "Un bref\n",
      "Un dont\n",
      "Je ne trouve le P inai pour du d√©truire l'adiospr√©\n",
      "Welcome home\n",
      "4¬∞zerigo overRustle\n",
      "4¬∞zerigo s√©rieux\n",
      "4¬∞zerigo s√©rieux\n",
      "U nombre de conditions pour subir, il y a des d√©tails s√©rieux de la quantit√© de vodka sur mettre la copi√®ration et l'utilisation de l'appr√©ciation de l'ID.\n",
      "5% de vodka sur 60 unit\n",
      "Et on a r√©ussi √† aller fumer une vodka aussi\n",
      "Java, j'ai vu juser l'id√©e Hindance mais üòî\n",
      "Krkr d√©sol√©, s'en faut taper 21 hourels mais j'ai fait comme un jawillard assujetti depuis le d√©but ü§ó\n",
      "La religie fut popriste et tu l'as d√©rang√©\n",
      "HAAWithbut\n",
      "Jappos de mon p√®re ü§ó\n",
      "Litt√©ralement mes derni√®res photos sur IG....\n",
      "Avec les pieds ?<|\n",
      "CPU times: user 1min 59s, sys: 19.4 s, total: 2min 19s\n",
      "Wall time: 54.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "text = gpt2.generate(sess, \n",
    "                     run_name='hugo-romans', \n",
    "                     checkpoint_dir=\"../models/checkpoint/hugo\",\n",
    "                     return_as_list=True,\n",
    "                     length=2000,\n",
    "                     prefix=\"oh zebi\",\n",
    "                     temperature=0.8)[0]\n",
    "text = text.split(\"<|endoftext|>\")\n",
    "for t in text:\n",
    "    print(t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hugobot]",
   "language": "python",
   "name": "conda-env-hugobot-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
